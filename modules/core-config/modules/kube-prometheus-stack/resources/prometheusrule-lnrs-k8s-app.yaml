apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: lnrs-k8s-app
  labels:
    lnrs.io/monitoring-platform: core-prometheus
  namespace: monitoring
spec:
  groups:
    - name: lnrs-k8s-app.rules
      rules:
        - alert: KubernetesPodNotHealthy
          expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"})[5m:]) > 0
          for: 15m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes Pod not healthy"
            description: "Kubernetes Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesPodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 > 1
          for: 15m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes Pod crash looping"
            description: "The {{ $labels.container }} contianer on Kubernetes Pod {{ $labels.namespace }}/{{ $labels.pod }} has been restarting for 15 minutes.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesDaemonsetRolloutStuck
          expr: kube_daemonset_status_number_ready / kube_daemonset_status_desired_number_scheduled < 1 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes DaemonSet rollout stuck"
            description: "Some Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled or not ready.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesDaemonsetMisscheduled
          expr: kube_daemonset_status_number_misscheduled > 0
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes DaemonSet misscheduled"
            description: "Some Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesStatefulsetDown
          expr: (kube_statefulset_status_replicas_ready / kube_statefulset_status_replicas_current) != 1
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes StatefulSet down"
            description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} is down.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesStatefulsetReplicasMismatch
          expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes StatefulSet replicas mismatch"
            description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} does not have the expected number of replicas.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesStatefulsetGenerationMismatch
          expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes StatefulSet generation mismatch"
            description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesStatefulsetUpdateNotRolledOut
          expr: max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes StatefulSet update not rolled out"
            description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesDeploymentReplicasMismatch
          expr: kube_deployment_spec_replicas != kube_deployment_status_replicas_available
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes Deployment replicas mismatch"
            description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} does not have the expected number of replicas.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesDeploymentGenerationMismatch
          expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes Deployment generation mismatch"
            description: "Deployment{{ $labels.namespace }}/{{ $labels.deployment }} has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesHpaScalingAbility
          expr: kube_hpa_status_condition{condition="AbleToScale", status="false"} == 1
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes HPA scaling ability"
            description: "HPA {{ $labels.namespace }}/{{ $labels.hpa }} is unable to scale.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesHpaMetricAvailability
          expr: kube_hpa_status_condition{condition="ScalingActive", status="false"} == 1
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes HPA metric availability"
            description: "HPA {{ $labels.namespace }}/{{ $labels.hpa }} is not able to colelct metrics.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesHpaScaleCapability
          expr: kube_hpa_status_desired_replicas >= kube_hpa_spec_max_replicas
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes HPA scale capability"
            description: "The maximum number of desired Pods has been hit for HPA {{ $labels.namespace }}/{{ $labels.hpa }}.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesJobFailed
          expr: kube_job_status_failed > 0
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes Job failed"
            description: "Kubernetes Job {{$labels.namespace}}/{{$labels.job_name}} failed to complete.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesJobCompletion
          expr: kube_job_spec_completions - kube_job_status_succeeded > 0 or kube_job_status_failed > 0
          for: 5m
          labels:
            severity: critical
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes Job not completed"
            description: "Kubernetes Job {{$labels.namespace}}/{{$labels.job_name}} failed to complete.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesCronjobSuspended
          expr: kube_cronjob_spec_suspend != 0
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes CronJob suspended"
            description: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubernetesCronjobTooLong
          expr: time() - kube_cronjob_next_schedule_time > 3600
          for: 5m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes CronJob too long"
            description: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more than 1 hour to complete.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

        - alert: KubeQuotaFullyUsed
          expr: kube_resourcequota{type="used"} / ignoring(instance, job, type) (kube_resourcequota{type="hard"} > 0) >= 1
          for: 15m
          labels:
            severity: warning
            namespace: "{{ $labels.namespace }}"
          annotations:
            summary: "Kubernetes namespace quota fully used"
            description: "Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
